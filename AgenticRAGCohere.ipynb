{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMhO5xUfBxAL3zE61hoCPQu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christymanthara/AgenticRag-with-Cohere/blob/newTools/AgenticRAGCohere.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpGySNRHlv2S",
        "outputId": "242b1b68-e71d-4e52-81c2-30836b5a57b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.7/973.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.9/307.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m974.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain langchain_openai langgraph arxiv duckduckgo-search\n",
        "!pip install -qU faiss-cpu pymupdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain-cohere"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtxQynJYtVBb",
        "outputId": "f4a543be-6335-4869-ce69-62d2a00f2736"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-cohere\n",
            "  Downloading langchain_cohere-0.1.5-py3-none-any.whl (30 kB)\n",
            "Collecting cohere<6.0,>=5.5 (from langchain-cohere)\n",
            "  Downloading cohere-5.5.0-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.5/158.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.3,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (0.2.0)\n",
            "Collecting boto3<2.0.0,>=1.34.0 (from cohere<6.0,>=5.5->langchain-cohere)\n",
            "  Downloading boto3-1.34.110-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.5->langchain-cohere)\n",
            "  Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5->langchain-cohere) (0.27.0)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from cohere<6.0,>=5.5->langchain-cohere)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5->langchain-cohere) (2.7.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5->langchain-cohere) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5->langchain-cohere) (0.19.1)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.5->langchain-cohere)\n",
            "  Downloading types_requests-2.32.0.20240521-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5->langchain-cohere) (4.11.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.42->langchain-cohere) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.42->langchain-cohere) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.42->langchain-cohere) (0.1.60)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.42->langchain-cohere) (23.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.42->langchain-cohere) (8.3.0)\n",
            "Collecting botocore<1.35.0,>=1.34.110 (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5->langchain-cohere)\n",
            "  Downloading botocore-1.34.110-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5->langchain-cohere)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5->langchain-cohere)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5->langchain-cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5->langchain-cohere) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5->langchain-cohere) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5->langchain-cohere) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5->langchain-cohere) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere<6.0,>=5.5->langchain-cohere) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.42->langchain-cohere) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.42->langchain-cohere) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere<6.0,>=5.5->langchain-cohere) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere<6.0,>=5.5->langchain-cohere) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5->langchain-cohere) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5->langchain-cohere) (2.0.7)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<0.20,>=0.19->cohere<6.0,>=5.5->langchain-cohere) (0.23.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.110->boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5->langchain-cohere) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.20,>=0.19->cohere<6.0,>=5.5->langchain-cohere) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.20,>=0.19->cohere<6.0,>=5.5->langchain-cohere) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.20,>=0.19->cohere<6.0,>=5.5->langchain-cohere) (4.66.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere<6.0,>=5.5->langchain-cohere) (1.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.110->boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5->langchain-cohere) (1.16.0)\n",
            "Installing collected packages: types-requests, jmespath, httpx-sse, fastavro, botocore, s3transfer, boto3, cohere, langchain-cohere\n",
            "Successfully installed boto3-1.34.110 botocore-1.34.110 cohere-5.5.0 fastavro-1.9.4 httpx-sse-0.4.0 jmespath-1.0.1 langchain-cohere-0.1.5 s3transfer-0.10.1 types-requests-2.32.0.20240521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_cohere import ChatCohere\n",
        "llm = ChatCohere(cohere_api_key=\"ckHImzP6pm5GmqHOer9IAuAJhXPP05coM729kPac\")"
      ],
      "metadata": {
        "id": "_ow3BVl_tphz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from uuid import uuid4\n",
        "import os"
      ],
      "metadata": {
        "id": "1S_5SaWduArs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oNTKhjZw1an",
        "outputId": "ac1b3e50-43e4-47de-acfc-41921a5f502d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.6)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.0)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.60)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain_community) (0.2.0)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain_community) (2.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain_community) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain_community) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (2.18.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Installing collected packages: langchain_community\n",
            "Successfully installed langchain_community-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import ArxivLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_cohere.embeddings import CohereEmbeddings\n",
        "\n",
        "# Load the document pertaining to a particular topic\n",
        "docs = ArxivLoader(query=\"Retrieval Augmented Generation\", load_max_docs=5).load()\n",
        "\n",
        "# Split the dpocument into smaller chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=350, chunk_overlap=50\n",
        ")\n",
        "\n",
        "chunked_documents = text_splitter.split_documents(docs)\n",
        "#\n",
        "# Instantiate the Embedding Model\n",
        "embeddings = CohereEmbeddings(model=\"embed-english-light-v3.0\",cohere_api_key=\"ckHImzP6pm5GmqHOer9IAuAJhXPP05coM729kPac\")\n",
        "# Create Index- Load document chunks into the vectorstore\n",
        "faiss_vectorstore = FAISS.from_documents(\n",
        "    documents=chunked_documents,\n",
        "    embedding=embeddings,\n",
        ")\n",
        "# Create a retriver\n",
        "retriever = faiss_vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "Bs9Pot8BwhZC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate RAG prompt"
      ],
      "metadata": {
        "id": "MI0y3AP9ySqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_PROMPT = \"\"\"\\\n",
        "Use the following context to answer the user's query. If you cannot answer the question, please respond with 'I don't know'.\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)\n"
      ],
      "metadata": {
        "id": "XM-1akHvyU9B"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_cohere import ChatCohere"
      ],
      "metadata": {
        "id": "mLQcTdz-0GJW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##instantiating the large language model"
      ],
      "metadata": {
        "id": "eDrOGBxj1rof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "chat_model = ChatCohere(cohere_api_key=\"ckHImzP6pm5GmqHOer9IAuAJhXPP05coM729kPac\")"
      ],
      "metadata": {
        "id": "niv-prEY06W9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "\n",
        "retrieval_augmented_generation_chain = (\n",
        "       {\"context\": itemgetter(\"question\")\n",
        "    | retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")\n",
        "#\n",
        "retrieval_augmented_generation_chain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRZkBFcL15BT",
        "outputId": "d34eda87-06e9-493b-f5e9-2d5d32df9151"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\n",
              "  context: RunnableLambda(itemgetter('question'))\n",
              "           | VectorStoreRetriever(tags=['FAISS', 'CohereEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x794f9e5d0eb0>),\n",
              "  question: RunnableLambda(itemgetter('question'))\n",
              "}\n",
              "| RunnableAssign(mapper={\n",
              "    context: RunnableLambda(itemgetter('context'))\n",
              "  })\n",
              "| {\n",
              "    response: ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"Use the following context to answer the user's query. If you cannot answer the question, please respond with 'I don't know'.\\n\\nQuestion:\\n{question}\\n\\nContext:\\n{context}\\n\"))])\n",
              "              | ChatCohere(client=<cohere.client.Client object at 0x794fa6837cd0>, async_client=<cohere.client.AsyncClient object at 0x794fa6837df0>, cohere_api_key=SecretStr('**********')),\n",
              "    context: RunnableLambda(itemgetter('context'))\n",
              "  }"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"\""
      ],
      "metadata": {
        "id": "9JJdybPjPaJF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "await retrieval_augmented_generation_chain.ainvoke({\"question\" : \"What is Retrieval Augmented Generation?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Syl8vDS10ZQ",
        "outputId": "8b1edaca-820b-4aa9-c6b9-b69f013a6f4a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'response': AIMessage(content=\"Retrieval Augmented Generation (RAG) is a technique used to improve the performance of Large Language Models (LLMs) by retrieving relevant tools or information for a given task. It addresses the limitation of LLMs, which require access to the right tools to solve new tasks with just a few examples. RAG employs a retrieval system to fetch relevant information or tools, enhancing the model's ability to generate responses. It has been applied to various natural language processing (NLP) tasks, including dialogue response generation and machine translation, achieving state-of-the-art performance.\", additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'ff682635-5c95-4c84-8759-ae27fc8f966c', 'token_count': {'input_tokens': 2644, 'output_tokens': 114}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'ff682635-5c95-4c84-8759-ae27fc8f966c', 'token_count': {'input_tokens': 2644, 'output_tokens': 114}}, id='run-c8ef2366-df27-4fd4-9924-2a731d029aa4-0'),\n",
              " 'context': [Document(page_content='Corrective Retrieval Augmented Generation\\nShi-Qi Yan1*, Jia-Chen Gu2*, Yun Zhu3, Zhen-Hua Ling1\\n1National Engineering Research Center of Speech and Language Information Processing,\\nUniversity of Science and Technology of China, Hefei, China\\n2Department of Computer Science, University of California, Los Angeles\\n3Google Research\\nyansiki@mail.ustc.edu.cn, gujc@ucla.edu, yunzhu@google.com, zhling@ustc.edu.cn\\nAbstract\\nLarge language models (LLMs) inevitably\\nexhibit hallucinations since the accuracy of\\ngenerated texts cannot be secured solely by\\nthe parametric knowledge they encapsulate. Al-\\nthough retrieval-augmented generation (RAG)\\nis a practicable complement to LLMs, it relies\\nheavily on the relevance of retrieved docu-\\nments, raising concerns about how the model\\nbehaves if retrieval goes wrong. To this end, we\\npropose the Corrective Retrieval Augmented\\nGeneration (CRAG) to improve the robustness\\nof generation.\\nSpecifically, a lightweight\\nretrieval evaluator is designed to assess the\\noverall quality of retrieved documents for a\\nquery, returning a confidence degree based\\non which different knowledge retrieval ac-\\ntions can be triggered. Since retrieval from\\nstatic and limited corpora can only return sub-\\noptimal documents, large-scale web searches\\nare utilized as an extension for augmenting the\\nretrieval results. Besides, a decompose-then-\\nrecompose algorithm is designed for retrieved', metadata={'Published': '2024-02-16', 'Title': 'Corrective Retrieval Augmented Generation', 'Authors': 'Shi-Qi Yan, Jia-Chen Gu, Yun Zhu, Zhen-Hua Ling', 'Summary': 'Large language models (LLMs) inevitably exhibit hallucinations since the\\naccuracy of generated texts cannot be secured solely by the parametric\\nknowledge they encapsulate. Although retrieval-augmented generation (RAG) is a\\npracticable complement to LLMs, it relies heavily on the relevance of retrieved\\ndocuments, raising concerns about how the model behaves if retrieval goes\\nwrong. To this end, we propose the Corrective Retrieval Augmented Generation\\n(CRAG) to improve the robustness of generation. Specifically, a lightweight\\nretrieval evaluator is designed to assess the overall quality of retrieved\\ndocuments for a query, returning a confidence degree based on which different\\nknowledge retrieval actions can be triggered. Since retrieval from static and\\nlimited corpora can only return sub-optimal documents, large-scale web searches\\nare utilized as an extension for augmenting the retrieval results. Besides, a\\ndecompose-then-recompose algorithm is designed for retrieved documents to\\nselectively focus on key information and filter out irrelevant information in\\nthem. CRAG is plug-and-play and can be seamlessly coupled with various\\nRAG-based approaches. Experiments on four datasets covering short- and\\nlong-form generation tasks show that CRAG can significantly improve the\\nperformance of RAG-based approaches.'}),\n",
              "  Document(page_content='grating translation memory to NMT models (Gu\\net al., 2018; Zhang et al., 2018; Xu et al., 2020;\\nHe et al., 2021). We also review the applications\\nof retrieval-augmented generation in other genera-\\ntion tasks such as abstractive summarization (Peng\\net al., 2019), code generation (Hashimoto et al.,\\n2018), paraphrase (Kazemnejad et al., 2020; Su\\net al., 2021b), and knowledge-intensive generation\\n(Lewis et al., 2020b). Finally, we also point out\\nsome promising directions on retrieval-augmented\\ngeneration to push forward the future research.\\n2\\nRetrieval-Augmented Paradigm\\nIn this section, we ﬁrst give a general formulation\\nof retrieval-augmented text generation. Then, we\\ndiscuss three major components of the retrieval-\\naugmented generation paradigm, including the re-\\narXiv:2202.01110v2  [cs.CL]  13 Feb 2022\\nInput\\nSources \\n(Sec. 2.2):\\nTraining \\nCorpus\\nExternal Data\\nUnsupervised \\nData\\nMetrics\\n(Sec. 2.3):\\nSparse-vector \\nRetrieval\\nDense-vector \\nRetrieval\\nTask-specific \\nRetrieval\\nRetrieval Memory\\nGeneration Model\\nSec. 4: Machine \\nTranslation\\nSec. 5: Other \\nTasks\\nData \\nAugmentation\\nAttention \\nMechanism\\nSkeleton & \\nTemplates\\nInformation Retrieval', metadata={'Published': '2022-02-13', 'Title': 'A Survey on Retrieval-Augmented Text Generation', 'Authors': 'Huayang Li, Yixuan Su, Deng Cai, Yan Wang, Lemao Liu', 'Summary': 'Recently, retrieval-augmented text generation attracted increasing attention\\nof the computational linguistics community. Compared with conventional\\ngeneration models, retrieval-augmented text generation has remarkable\\nadvantages and particularly has achieved state-of-the-art performance in many\\nNLP tasks. This paper aims to conduct a survey about retrieval-augmented text\\ngeneration. It firstly highlights the generic paradigm of retrieval-augmented\\ngeneration, and then it reviews notable approaches according to different tasks\\nincluding dialogue response generation, machine translation, and other\\ngeneration tasks. Finally, it points out some important directions on top of\\nrecent methods to facilitate future research.'}),\n",
              "  Document(page_content='Context Tuning for Retrieval Augmented Generation\\nRaviteja Anantha, Tharun Bethi, Danil Vodianik, Srinivas Chappidi\\nApple\\nAbstract\\nLarge language models (LLMs) have the re-\\nmarkable ability to solve new tasks with just a\\nfew examples, but they need access to the right\\ntools. Retrieval Augmented Generation (RAG)\\naddresses this problem by retrieving a list of\\nrelevant tools for a given task. However, RAG’s\\ntool retrieval step requires all the required in-\\nformation to be explicitly present in the query.\\nThis is a limitation, as semantic search, the\\nwidely adopted tool retrieval method, can fail\\nwhen the query is incomplete or lacks context.\\nTo address this limitation, we propose Context\\nTuning for RAG, which employs a smart con-\\ntext retrieval system to fetch relevant informa-\\ntion that improves both tool retrieval and plan\\ngeneration. Our lightweight context retrieval\\nmodel uses numerical, categorical, and habitual\\nusage signals to retrieve and rank context items.\\nOur empirical results demonstrate that context\\ntuning significantly enhances semantic search,\\nachieving a 3.5-fold and 1.5-fold improvement\\nin Recall@K for context retrieval and tool re-\\ntrieval tasks respectively, and resulting in an\\n11.6% increase in LLM-based planner accu-\\nracy. Additionally, we show that our proposed\\nlightweight model using Reciprocal Rank Fu-\\nsion (RRF) with LambdaMART outperforms\\nGPT-4 based retrieval. Moreover, we observe', metadata={'Published': '2023-12-09', 'Title': 'Context Tuning for Retrieval Augmented Generation', 'Authors': 'Raviteja Anantha, Tharun Bethi, Danil Vodianik, Srinivas Chappidi', 'Summary': \"Large language models (LLMs) have the remarkable ability to solve new tasks\\nwith just a few examples, but they need access to the right tools. Retrieval\\nAugmented Generation (RAG) addresses this problem by retrieving a list of\\nrelevant tools for a given task. However, RAG's tool retrieval step requires\\nall the required information to be explicitly present in the query. This is a\\nlimitation, as semantic search, the widely adopted tool retrieval method, can\\nfail when the query is incomplete or lacks context. To address this limitation,\\nwe propose Context Tuning for RAG, which employs a smart context retrieval\\nsystem to fetch relevant information that improves both tool retrieval and plan\\ngeneration. Our lightweight context retrieval model uses numerical,\\ncategorical, and habitual usage signals to retrieve and rank context items. Our\\nempirical results demonstrate that context tuning significantly enhances\\nsemantic search, achieving a 3.5-fold and 1.5-fold improvement in Recall@K for\\ncontext retrieval and tool retrieval tasks respectively, and resulting in an\\n11.6% increase in LLM-based planner accuracy. Additionally, we show that our\\nproposed lightweight model using Reciprocal Rank Fusion (RRF) with LambdaMART\\noutperforms GPT-4 based retrieval. Moreover, we observe context augmentation at\\nplan generation, even after tool retrieval, reduces hallucination.\"}),\n",
              "  Document(page_content='A Survey on Retrieval-Augmented Text Generation\\nHuayang Li♥,∗\\nYixuan Su♠,∗\\nDeng Cai♦,∗\\nYan Wang♣,∗\\nLemao Liu♣,∗\\n♥Nara Institute of Science and Technology\\n♠University of Cambridge\\n♦The Chinese University of Hong Kong\\n♣Tencent AI Lab\\nli.huayang.lh6@is.naist.jp, ys484@cam.ac.uk\\nthisisjcykcd@gmail.com, brandenwang@tencent.com\\nlemaoliu@gmail.com\\nAbstract\\nRecently, retrieval-augmented text generation\\nattracted increasing attention of the compu-\\ntational linguistics community.\\nCompared\\nwith conventional generation models, retrieval-\\naugmented text generation has remarkable ad-\\nvantages and particularly has achieved state-of-\\nthe-art performance in many NLP tasks. This\\npaper aims to conduct a survey about retrieval-\\naugmented text generation. It ﬁrstly highlights\\nthe generic paradigm of retrieval-augmented\\ngeneration, and then it reviews notable ap-\\nproaches according to different tasks including\\ndialogue response generation, machine trans-\\nlation, and other generation tasks. Finally, it\\npoints out some promising directions on top of\\nrecent methods to facilitate future research.\\n1\\nIntroduction\\nRetrieval-augmented text generation, as a new\\ntext generation paradigm that fuses emerging deep\\nlearning technology and traditional retrieval tech-', metadata={'Published': '2022-02-13', 'Title': 'A Survey on Retrieval-Augmented Text Generation', 'Authors': 'Huayang Li, Yixuan Su, Deng Cai, Yan Wang, Lemao Liu', 'Summary': 'Recently, retrieval-augmented text generation attracted increasing attention\\nof the computational linguistics community. Compared with conventional\\ngeneration models, retrieval-augmented text generation has remarkable\\nadvantages and particularly has achieved state-of-the-art performance in many\\nNLP tasks. This paper aims to conduct a survey about retrieval-augmented text\\ngeneration. It firstly highlights the generic paradigm of retrieval-augmented\\ngeneration, and then it reviews notable approaches according to different tasks\\nincluding dialogue response generation, machine translation, and other\\ngeneration tasks. Finally, it points out some important directions on top of\\nrecent methods to facilitate future research.'})]}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.ddg_search import DuckDuckGoSearchRun\n",
        "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
        "from langgraph.prebuilt import ToolExecutor\n",
        "tool_belt = [\n",
        "    DuckDuckGoSearchRun(),\n",
        "    ArxivQueryRun()\n",
        "]\n",
        "\n",
        "tool_executor = ToolExecutor(tool_belt)"
      ],
      "metadata": {
        "id": "nBHz-IGO2VOX"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet  arxiv"
      ],
      "metadata": {
        "id": "nI2LEQHWFQWw"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchainhub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq5VGhphIe3x",
        "outputId": "33d07c66-06ad-4155-827f-2c4839e80d89"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchainhub in /usr/local/lib/python3.10/dist-packages (0.1.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (2.31.0)\n",
            "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (2.32.0.20240521)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet  duckduckgo-search"
      ],
      "metadata": {
        "id": "iECg2IHZJaLk"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_react_agent, load_tools\n",
        "from langchain_cohere.react_multi_hop.agent import create_cohere_react_agent\n",
        "from langchain_cohere.chat_models import ChatCohere\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
        "chat_model = ChatCohere(cohere_api_key=\"ckHImzP6pm5GmqHOer9IAuAJhXPP05coM729kPac\")\n",
        "\n",
        "llm = ChatCohere(model=\"command-r-plus\", temperature=0.3,cohere_api_key=\"ckHImzP6pm5GmqHOer9IAuAJhXPP05coM729kPac\")\n",
        "# tools = load_tools(\n",
        "#     [\"duckduckgo-search\"],[\"arxiv\"]\n",
        "# )\n",
        "# prompt = hub.pull(\"hwchase17/react\")\n",
        "\n",
        "duckSearch = DuckDuckGoSearchRun()\n",
        "duckSearch.name = \"search_engine\"\n",
        "duckSearch.description = \"returns a string as the answer\";\n",
        "\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "class DuckSearchInput(BaseModel):\n",
        "   query: str = Field(description=\"Query to search the internet with\")\n",
        "duckSearch.args_schema = DuckSearchInput\n",
        "\n",
        "\n",
        "#arxiv invoking\n",
        "\n",
        "\n",
        "arxivSearch = ArxivQueryRun()\n",
        "arxivSearch.name = \"Docs_search\";\n",
        "arxivSearch.description = \"returns the paper data as the output\";\n",
        "class arxivInput(BaseModel):\n",
        "  query:str = Field(description=\"Query to search the arxiv with\")\n",
        "arxivSearch.args_schema = arxivInput;\n",
        "\n",
        "# tools = [duckSearch,arxivSearch]\n",
        "\n",
        "\n",
        "tools = [arxivSearch,duckSearch]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oOrAQaPPEhgY"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preamble = \"\"\"\n",
        "You are an expert who answers the user's question with the most relevant datasource.\n",
        "You are equipped with an internet search tool and a special vectorstore of information\n",
        "about how to write good essays.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "T_l-NfNkDOld"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
        "agent = create_cohere_react_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ],
      "metadata": {
        "id": "7QZqd7I2UCyy"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke({\n",
        "   \"input\": \"can you find me five papers about RAG?\",\n",
        "   \"preamble\": preamble,\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGQfSWG3KD6_",
        "outputId": "de5dd338-53d3-4627-8711-738fd332e037"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "I will search for five papers about RAG and write an answer based on the results.\n",
            "{'tool_name': 'Docs_search', 'parameters': {'query': 'RAG'}}\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mPublished: 2024-01-27\n",
            "Title: MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries\n",
            "Authors: Yixuan Tang, Yi Yang\n",
            "Summary: Retrieval-augmented generation (RAG) augments large language models (LLM) by\n",
            "retrieving relevant knowledge, showing promising potential in mitigating LLM\n",
            "hallucinations and enhancing response quality, thereby facilitating the great\n",
            "adoption of LLMs in practice. However, we find that existing RAG systems are\n",
            "inadequate in answering multi-hop queries, which require retrieving and\n",
            "reasoning over multiple pieces of supporting evidence. Furthermore, to our\n",
            "knowledge, no existing RAG benchmarking dataset focuses on multi-hop queries.\n",
            "In this paper, we develop a novel dataset, MultiHop-RAG, which consists of a\n",
            "knowledge base, a large collection of multi-hop queries, their ground-truth\n",
            "answers, and the associated supporting evidence. We detail the procedure of\n",
            "building the dataset, utilizing an English news article dataset as the\n",
            "underlying RAG knowledge base. We demonstrate the benchmarking utility of\n",
            "MultiHop-RAG in two experiments. The first experiment compares different\n",
            "embedding models for retrieving evidence for multi-hop queries. In the second\n",
            "experiment, we examine the capabilities of various state-of-the-art LLMs,\n",
            "including GPT-4, PaLM, and Llama2-70B, in reasoning and answering multi-hop\n",
            "queries given the evidence. Both experiments reveal that existing RAG methods\n",
            "perform unsatisfactorily in retrieving and answering multi-hop queries. We hope\n",
            "MultiHop-RAG will be a valuable resource for the community in developing\n",
            "effective RAG systems, thereby facilitating greater adoption of LLMs in\n",
            "practice. The MultiHop-RAG and implemented RAG system is publicly available at\n",
            "https://github.com/yixuantt/MultiHop-RAG/.\n",
            "\n",
            "Published: 2024-05-02\n",
            "Title: Retrieval-Augmented Generation for AI-Generated Content: A Survey\n",
            "Authors: Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao Zhang, Jie Jiang, Bin Cui\n",
            "Summary: Advancements in model algorithms, the growth of foundational models, and\n",
            "access to high-quality datasets have propelled the evolution of Artificial\n",
            "Intelligence Generated Content (AIGC). Despite its notable successes, AIGC\n",
            "still faces hurdles such as updating knowledge, handling long-tail data,\n",
            "mitigating data leakage, and managing high training and inference costs.\n",
            "Retrieval-Augmented Generation (RAG) has recently emerged as a paradigm to\n",
            "address such challenges. In particular, RAG introduces the information\n",
            "retrieval process, which enhances the generation process by retrieving relevant\n",
            "objects from available data stores, leading to higher accuracy and better\n",
            "robustness. In this paper, we comprehensively review existing efforts that\n",
            "integrate RAG technique into AIGC scenarios. We first classify RAG foundations\n",
            "according to how the retriever augments the generator, distilling the\n",
            "fundamental abstractions of the augmentation methodologies for various\n",
            "retrievers and generators. This unified perspective encompasses all RAG\n",
            "scenarios, illuminating advancements and pivotal technologies that help with\n",
            "potential future progress. We also summarize additional enhancements methods\n",
            "for RAG, facilitating effective engineering and implementation of RAG systems.\n",
            "Then from another view, we survey on practical applications of RAG across\n",
            "different modalities and tasks, offering valuable references for researchers\n",
            "and practitioners. Furthermore, we introduce the benchmarks for RAG, discuss\n",
            "the limitations of current RAG systems, and suggest potential directions for\n",
            "future research. Github: https://github.com/PKU-DAIR/RAG-Survey.\n",
            "\n",
            "Published: 2024-01-11\n",
            "Title: Seven Failure Points When Engineering a Retrieval Augmented Generation System\n",
            "Authors: Scott Barnett, Stefanus Kurniawan, Srikanth Thudumu, Zach Brannelly, Mohamed Abdelrazek\n",
            "Summary: Software engineers are increasingly adding semantic search capabilities to\n",
            "applications using a strategy known as Retrieval A\u001b[0m\u001b[32;1m\u001b[1;3mRelevant Documents: 0\n",
            "Cited Documents: 0\n",
            "Answer: Here are five papers about RAG:\n",
            "\n",
            "1. *MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries* by Yixuan Tang and Yi Yang\n",
            "2. *Retrieval-Augmented Generation for AI-Generated Content: A Survey* by Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao Zhang, Jie Jiang, and Bin Cui\n",
            "3. *Seven Failure Points When Engineering a Retrieval Augmented Generation System* by Scott Barnett, Stefanus Kurniawan, Srikanth Thudumu, Zach Brannelly, and Mohamed Abdelrazek\n",
            "4. *RAG: Retrieval Augmented Generation for Knowledge-Intensive NLP Tasks* by Yixuan Tang, Yi Yang, and Wen-tau Yih\n",
            "5. *RAG-Token: Retrieval Augmented Generation with Token-Level Retrievers* by Yixuan Tang, Yi Yang, and Wen-tau Yih\n",
            "Grounded answer: Here are five papers about RAG:\n",
            "\n",
            "1. <co: 0>*MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries</co: 0>* by <co: 0>Yixuan Tang and Yi Yang</co: 0>\n",
            "2. <co: 0>*Retrieval-Augmented Generation for AI-Generated Content: A Survey</co: 0>* by <co: 0>Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao Zhang, Jie Jiang, and Bin Cui</co: 0>\n",
            "3. <co: 0>*Seven Failure Points When Engineering a Retrieval Augmented Generation System</co: 0>* by <co: 0>Scott Barnett, Stefanus Kurniawan, Srikanth Thudumu, Zach Brannelly, and Mohamed Abdelrazek</co: 0>\n",
            "4. <co: 0>*RAG: Retrieval Augmented Generation for Knowledge-Intensive NLP Tasks</co: 0>* by <co: 0>Yixuan Tang, Yi Yang, and Wen-tau Yih</co: 0>\n",
            "5. <co: 0>*RAG-Token: Retrieval Augmented Generation with Token-Level Retrievers</co: 0>* by <co: 0>Yixuan Tang, Yi Yang, and Wen-tau Yih</co: 0>\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'can you find me five papers about RAG?',\n",
              " 'preamble': \"\\nYou are an expert who answers the user's question with the most relevant datasource.\\nYou are equipped with an internet search tool and a special vectorstore of information\\nabout how to write good essays.\\n\",\n",
              " 'output': 'Here are five papers about RAG:\\n\\n1. *MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries* by Yixuan Tang and Yi Yang\\n2. *Retrieval-Augmented Generation for AI-Generated Content: A Survey* by Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao Zhang, Jie Jiang, and Bin Cui\\n3. *Seven Failure Points When Engineering a Retrieval Augmented Generation System* by Scott Barnett, Stefanus Kurniawan, Srikanth Thudumu, Zach Brannelly, and Mohamed Abdelrazek\\n4. *RAG: Retrieval Augmented Generation for Knowledge-Intensive NLP Tasks* by Yixuan Tang, Yi Yang, and Wen-tau Yih\\n5. *RAG-Token: Retrieval Augmented Generation with Token-Level Retrievers* by Yixuan Tang, Yi Yang, and Wen-tau Yih',\n",
              " 'citations': [CohereCitation(start=36, end=116, text='*MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries', documents=[{'output': 'Published: 2024-01-27\\nTitle: MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries\\nAuthors: Yixuan Tang, Yi Yang\\nSummary: Retrieval-augmented generation (RAG) augments large language models (LLM) by\\nretrieving relevant knowledge, showing promising potential in mitigating LLM\\nhallucinations and enhancing response quality, thereby facilitating the great\\nadoption of LLMs in practice. However, we find that existing RAG systems are\\ninadequate in answering multi-hop queries, which require retrieving and\\nreasoning over multiple pieces of supporting evidence. Furthermore, to our\\nknowledge, no existing RAG benchmarking dataset focuses on multi-hop queries.\\nIn this paper, we develop a novel dataset, MultiHop-RAG, which consists of a\\nknowledge base, a large collection of multi-hop queries, their ground-truth\\nanswers, and the associated supporting evidence. We detail the procedure of\\nbuilding the dataset, utilizing an English news article dataset as the\\nunderlying RAG knowledge base. We demonstrate the benchmarking utility of\\nMultiHop-RAG in two experiments. The first experiment compares different\\nembedding models for retrieving evidence for multi-hop queries. In the second\\nexperiment, we examine the capabilities of various state-of-the-art LLMs,\\nincluding GPT-4, PaLM, and Llama2-70B, in reasoning and answering multi-hop\\nqueries given the evidence. Both experiments reveal that existing RAG methods\\nperform unsatisfactorily in retrieving and answering multi-hop queries. We hope\\nMultiHop-RAG will be a valuable resource for the community in developing\\neffective RAG systems, thereby facilitating greater adoption of LLMs in\\npractice. The MultiHop-RAG and implemented RAG system is publicly available at\\nhttps://github.com/yixuantt/MultiHop-RAG/.\\n\\nPublished: 2024-05-02\\nTitle: Retrieval-Augmented Generation for AI-Generated Content: A Survey\\nAuthors: Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao Zhang, Jie Jiang, Bin Cui\\nSummary: Advancements in model algorithms, the growth of foundational models, and\\naccess to high-quality datasets have propelled the evolution of Artificial\\nIntelligence Generated Content (AIGC). Despite its notable successes, AIGC\\nstill faces hurdles such as updating knowledge, handling long-tail data,\\nmitigating data leakage, and managing high training and inference costs.\\nRetrieval-Augmented Generation (RAG) has recently emerged as a paradigm to\\naddress such challenges. In particular, RAG introduces the information\\nretrieval process, which enhances the generation process by retrieving relevant\\nobjects from available data stores, leading to higher accuracy and better\\nrobustness. In this paper, we comprehensively review existing efforts that\\nintegrate RAG technique into AIGC scenarios. We first classify RAG foundations\\naccording to how the retriever augments the generator, distilling the\\nfundamental abstractions of the augmentation methodologies for various\\nretrievers and generators. This unified perspective encompasses all RAG\\nscenarios, illuminating advancements and pivotal technologies that help with\\npotential future progress. We also summarize additional enhancements methods\\nfor RAG, facilitating effective engineering and implementation of RAG systems.\\nThen from another view, we survey on practical applications of RAG across\\ndifferent modalities and tasks, offering valuable references for researchers\\nand practitioners. Furthermore, we introduce the benchmarks for RAG, discuss\\nthe limitations of current RAG systems, and suggest potential directions for\\nfuture research. Github: https://github.com/PKU-DAIR/RAG-Survey.\\n\\nPublished: 2024-01-11\\nTitle: Seven Failure Points When Engineering a Retrieval Augmented Generation System\\nAuthors: Scott Barnett, Stefanus Kurniawan, Srikanth Thudumu, Zach Brannelly, Mohamed Abdelrazek\\nSummary: Software engineers are increasingly adding semantic search capabilities to\\napplications using a strategy known as Retrieval A', 'id': 'doc_0'}], document_ids={'doc_0'}),\n",
              "  CohereCitation(start=121, end=144, text='Yixuan Tang and Yi Yang', documents=[{'output': 'Published: 2024-01-27\\nTitle: MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries\\nAuthors: Yixuan Tang, Yi Yang\\nSummary: Retrieval-augmented generation (RAG) augments large language models (LLM) by\\nretrieving relevant knowledge, showing promising potential in mitigating LLM\\nhallucinations and enhancing response quality, thereby facilitating the great\\nadoption of LLMs in practice. However, we find that existing RAG systems are\\ninadequate in answering multi-hop queries, which require retrieving and\\nreasoning over multiple pieces of supporting evidence. Furthermore, to our\\nknowledge, no existing RAG benchmarking dataset focuses on multi-hop queries.\\nIn this paper, we develop a novel dataset, MultiHop-RAG, which consists of a\\nknowledge base, a large collection of multi-hop queries, their ground-truth\\nanswers, and the associated supporting evidence. We detail the procedure of\\nbuilding the dataset, utilizing an English news article dataset as the\\nunderlying RAG knowledge base. We demonstrate the benchmarking utility of\\nMultiHop-RAG in two experiments. The first experiment compares different\\nembedding models for retrieving evidence for multi-hop queries. In the second\\nexperiment, we examine the capabilities of various state-of-the-art LLMs,\\nincluding GPT-4, PaLM, and Llama2-70B, in reasoning and answering multi-hop\\nqueries given the evidence. Both experiments reveal that existing RAG methods\\nperform unsatisfactorily in retrieving and answering multi-hop queries. We hope\\nMultiHop-RAG will be a valuable resource for the community in developing\\neffective RAG systems, thereby facilitating greater adoption of LLMs in\\npractice. The MultiHop-RAG and implemented RAG system is publicly available at\\nhttps://github.com/yixuantt/MultiHop-RAG/.\\n\\nPublished: 2024-05-02\\nTitle: Retrieval-Augmented Generation for AI-Generated Content: A Survey\\nAuthors: Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao Zhang, Jie Jiang, Bin Cui\\nSummary: Advancements in model algorithms, the growth of foundational models, and\\naccess to high-quality datasets have propelled the evolution of Artificial\\nIntelligence Generated Content (AIGC). Despite its notable successes, AIGC\\nstill faces hurdles such as updating knowledge, handling long-tail data,\\nmitigating data leakage, and managing high training and inference costs.\\nRetrieval-Augmented Generation (RAG) has recently emerged as a paradigm to\\naddress such challenges. In particular, RAG introduces the information\\nretrieval process, which enhances the generation process by retrieving relevant\\nobjects from available data stores, leading to higher accuracy and better\\nrobustness. In this paper, we comprehensively review existing efforts that\\nintegrate RAG technique into AIGC scenarios. We first classify RAG foundations\\naccording to how the retriever augments the generator, distilling the\\nfundamental abstractions of the augmentation methodologies for various\\nretrievers and generators. This unified perspective encompasses all RAG\\nscenarios, illuminating advancements and pivotal technologies that help with\\npotential future progress. We also summarize additional enhancements methods\\nfor RAG, facilitating effective engineering and implementation of RAG systems.\\nThen from another view, we survey on practical applications of RAG across\\ndifferent modalities and tasks, offering valuable references for researchers\\nand practitioners. Furthermore, we introduce the benchmarks for RAG, discuss\\nthe limitations of current RAG systems, and suggest potential directions for\\nfuture research. Github: https://github.com/PKU-DAIR/RAG-Survey.\\n\\nPublished: 2024-01-11\\nTitle: Seven Failure Points When Engineering a Retrieval Augmented Generation System\\nAuthors: Scott Barnett, Stefanus Kurniawan, Srikanth Thudumu, Zach Brannelly, Mohamed Abdelrazek\\nSummary: Software engineers are increasingly adding semantic search capabilities to\\napplications using a strategy known as Retrieval A', 'id': 'doc_0'}], document_ids={'doc_0'}),\n",
              "  CohereCitation(start=148, end=214, text='*Retrieval-Augmented Generation for AI-Generated Content: A Survey', documents=[{'output': 'Published: 2024-01-27\\nTitle: MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries\\nAuthors: Yixuan Tang, Yi Yang\\nSummary: Retrieval-augmented generation (RAG) augments large language models (LLM) by\\nretrieving relevant knowledge, showing promising potential in mitigating LLM\\nhallucinations and enhancing response quality, thereby facilitating the great\\nadoption of LLMs in practice. However, we find that existing RAG systems are\\ninadequate in answering multi-hop queries, which require retrieving and\\nreasoning over multiple pieces of supporting evidence. Furthermore, to our\\nknowledge, no existing RAG benchmarking dataset focuses on multi-hop queries.\\nIn this paper, we develop a novel dataset, MultiHop-RAG, which consists of a\\nknowledge base, a large collection of multi-hop queries, their ground-truth\\nanswers, and the associated supporting evidence. We detail the procedure of\\nbuilding the dataset, utilizing an English news article dataset as the\\nunderlying RAG knowledge base. We demonstrate the benchmarking utility of\\nMultiHop-RAG in two experiments. The first experiment compares different\\nembedding models for retrieving evidence for multi-hop queries. In the second\\nexperiment, we examine the capabilities of various state-of-the-art LLMs,\\nincluding GPT-4, PaLM, and Llama2-70B, in reasoning and answering multi-hop\\nqueries given the evidence. Both experiments reveal that existing RAG methods\\nperform unsatisfactorily in retrieving and answering multi-hop queries. We hope\\nMultiHop-RAG will be a valuable resource for the community in developing\\neffective RAG systems, thereby facilitating greater adoption of LLMs in\\npractice. The MultiHop-RAG and implemented RAG system is publicly available at\\nhttps://github.com/yixuantt/MultiHop-RAG/.\\n\\nPublished: 2024-05-02\\nTitle: Retrieval-Augmented Generation for AI-Generated Content: A Survey\\nAuthors: Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao Zhang, Jie Jiang, Bin Cui\\nSummary: Advancements in model algorithms, the growth of foundational models, and\\naccess to high-quality datasets have propelled the evolution of Artificial\\nIntelligence Generated Content (AIGC). Despite its notable successes, AIGC\\nstill faces hurdles such as updating knowledge, handling long-tail data,\\nmitigating data leakage, and managing high training and inference costs.\\nRetrieval-Augmented Generation (RAG) has recently emerged as a paradigm to\\naddress such challenges. In particular, RAG introduces the information\\nretrieval process, which enhances the generation process by retrieving relevant\\nobjects from available data stores, leading to higher accuracy and better\\nrobustness. In this paper, we comprehensively review existing efforts that\\nintegrate RAG technique into AIGC scenarios. We first classify RAG foundations\\naccording to how the retriever augments the generator, distilling the\\nfundamental abstractions of the augmentation methodologies for various\\nretrievers and generators. This unified perspective encompasses all RAG\\nscenarios, illuminating advancements and pivotal technologies that help with\\npotential future progress. We also summarize additional enhancements methods\\nfor RAG, facilitating effective engineering and implementation of RAG systems.\\nThen from another view, we survey on practical applications of RAG across\\ndifferent modalities and tasks, offering valuable references for researchers\\nand practitioners. Furthermore, we introduce the benchmarks for RAG, discuss\\nthe limitations of current RAG systems, and suggest potential directions for\\nfuture research. Github: https://github.com/PKU-DAIR/RAG-Survey.\\n\\nPublished: 2024-01-11\\nTitle: Seven Failure Points When Engineering a Retrieval Augmented Generation System\\nAuthors: Scott Barnett, Stefanus Kurniawan, Srikanth Thudumu, Zach Brannelly, Mohamed Abdelrazek\\nSummary: Software engineers are increasingly adding semantic search capabilities to\\napplications using a strategy known as Retrieval A', 'id': 'doc_0'}], document_ids={'doc_0'}),\n",
              "  CohereCitation(start=219, end=348, text='Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao Zhang, Jie Jiang, and Bin Cui', documents=[{'output': 'Published: 2024-01-27\\nTitle: MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries\\nAuthors: Yixuan Tang, Yi Yang\\nSummary: Retrieval-augmented generation (RAG) augments large language models (LLM) by\\nretrieving relevant knowledge, showing promising potential in mitigating LLM\\nhallucinations and enhancing response quality, thereby facilitating the great\\nadoption of LLMs in practice. However, we find that existing RAG systems are\\ninadequate in answering multi-hop queries, which require retrieving and\\nreasoning over multiple pieces of supporting evidence. Furthermore, to our\\nknowledge, no existing RAG benchmarking dataset focuses on multi-hop queries.\\nIn this paper, we develop a novel dataset, MultiHop-RAG, which consists of a\\nknowledge base, a large collection of multi-hop queries, their ground-truth\\nanswers, and the associated supporting evidence. We detail the procedure of\\nbuilding the dataset, utilizing an English news article dataset as the\\nunderlying RAG knowledge base. We demonstrate the benchmarking utility of\\nMultiHop-RAG in two experiments. The first experiment compares different\\nembedding models for retrieving evidence for multi-hop queries. In the second\\nexperiment, we examine the capabilities of various state-of-the-art LLMs,\\nincluding GPT-4, PaLM, and Llama2-70B, in reasoning and answering multi-hop\\nqueries given the evidence. Both experiments reveal that existing RAG methods\\nperform unsatisfactorily in retrieving and answering multi-hop queries. We hope\\nMultiHop-RAG will be a valuable resource for the community in developing\\neffective RAG systems, thereby facilitating greater adoption of LLMs in\\npractice. The MultiHop-RAG and implemented RAG system is publicly available at\\nhttps://github.com/yixuantt/MultiHop-RAG/.\\n\\nPublished: 2024-05-02\\nTitle: Retrieval-Augmented Generation for AI-Generated Content: A Survey\\nAuthors: Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao Zhang, Jie Jiang, Bin Cui\\nSummary: Advancements in model algorithms, the growth of foundational models, and\\naccess to high-quality datasets have propelled the evolution of Artificial\\nIntelligence Generated Content (AIGC). Despite its notable successes, AIGC\\nstill faces hurdles such as updating knowledge, handling long-tail data,\\nmitigating data leakage, and managing high training and inference costs.\\nRetrieval-Augmented Generation (RAG) has recently emerged as a paradigm to\\naddress such challenges. In particular, RAG introduces the information\\nretrieval process, which enhances the generation process by retrieving relevant\\nobjects from available data stores, leading to higher accuracy and better\\nrobustness. In this paper, we comprehensively review existing efforts that\\nintegrate RAG technique into AIGC scenarios. We first classify RAG foundations\\naccording to how the retriever augments the generator, distilling the\\nfundamental abstractions of the augmentation methodologies for various\\nretrievers and generators. This unified perspective encompasses all RAG\\nscenarios, illuminating advancements and pivotal technologies that help with\\npotential future progress. We also summarize additional enhancements methods\\nfor RAG, facilitating effective engineering and implementation of RAG systems.\\nThen from another view, we survey on practical applications of RAG across\\ndifferent modalities and tasks, offering valuable references for researchers\\nand practitioners. Furthermore, we introduce the benchmarks for RAG, discuss\\nthe limitations of current RAG systems, and suggest potential directions for\\nfuture research. Github: https://github.com/PKU-DAIR/RAG-Survey.\\n\\nPublished: 2024-01-11\\nTitle: Seven Failure Points When Engineering a Retrieval Augmented Generation System\\nAuthors: Scott Barnett, Stefanus Kurniawan, Srikanth Thudumu, Zach Brannelly, Mohamed Abdelrazek\\nSummary: Software engineers are increasingly adding semantic search capabilities to\\napplications using a strategy known as Retrieval A', 'id': 'doc_0'}], document_ids={'doc_0'}),\n",
              "  CohereCitation(start=352, end=430, text='*Seven Failure Points When Engineering a Retrieval Augmented Generation System', documents=[{'output': 'Published: 2024-01-27\\nTitle: MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries\\nAuthors: Yixuan Tang, Yi Yang\\nSummary: Retrieval-augmented generation (RAG) augments large language models (LLM) by\\nretrieving relevant knowledge, showing promising potential in mitigating LLM\\nhallucinations and enhancing response quality, thereby facilitating the great\\nadoption of LLMs in practice. However, we find that existing RAG systems are\\ninadequate in answering multi-hop queries, which require retrieving and\\nreasoning over multiple pieces of supporting evidence. Furthermore, to our\\nknowledge, no existing RAG benchmarking dataset focuses on multi-hop queries.\\nIn this paper, we develop a novel dataset, MultiHop-RAG, which consists of a\\nknowledge base, a large collection of multi-hop queries, their ground-truth\\nanswers, and the associated supporting evidence. We detail the procedure of\\nbuilding the dataset, utilizing an English news article dataset as the\\nunderlying RAG knowledge base. We demonstrate the benchmarking utility of\\nMultiHop-RAG in two experiments. The first experiment compares different\\nembedding models for retrieving evidence for multi-hop queries. In the second\\nexperiment, we examine the capabilities of various state-of-the-art LLMs,\\nincluding GPT-4, PaLM, and Llama2-70B, in reasoning and answering multi-hop\\nqueries given the evidence. Both experiments reveal that existing RAG methods\\nperform unsatisfactorily in retrieving and answering multi-hop queries. We hope\\nMultiHop-RAG will be a valuable resource for the community in developing\\neffective RAG systems, thereby facilitating greater adoption of LLMs in\\npractice. The MultiHop-RAG and implemented RAG system is publicly available at\\nhttps://github.com/yixuantt/MultiHop-RAG/.\\n\\nPublished: 2024-05-02\\nTitle: Retrieval-Augmented Generation for AI-Generated Content: A Survey\\nAuthors: Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao Zhang, Jie Jiang, Bin Cui\\nSummary: Advancements in model algorithms, the growth of foundational models, and\\naccess to high-quality datasets have propelled the evolution of Artificial\\nIntelligence Generated Content (AIGC). Despite its notable successes, AIGC\\nstill faces hurdles such as updating knowledge, handling long-tail data,\\nmitigating data leakage, and managing high training and inference costs.\\nRetrieval-Augmented Generation (RAG) has recently emerged as a paradigm to\\naddress such challenges. In particular, RAG introduces the information\\nretrieval process, which enhances the generation process by retrieving relevant\\nobjects from available data stores, leading to higher accuracy and better\\nrobustness. In this paper, we comprehensively review existing efforts that\\nintegrate RAG technique into AIGC scenarios. We first classify RAG foundations\\naccording to how the retriever augments the generator, distilling the\\nfundamental abstractions of the augmentation methodologies for various\\nretrievers and generators. This unified perspective encompasses all RAG\\nscenarios, illuminating advancements and pivotal technologies that help with\\npotential future progress. We also summarize additional enhancements methods\\nfor RAG, facilitating effective engineering and implementation of RAG systems.\\nThen from another view, we survey on practical applications of RAG across\\ndifferent modalities and tasks, offering valuable references for researchers\\nand practitioners. Furthermore, we introduce the benchmarks for RAG, discuss\\nthe limitations of current RAG systems, and suggest potential directions for\\nfuture research. Github: https://github.com/PKU-DAIR/RAG-Survey.\\n\\nPublished: 2024-01-11\\nTitle: Seven Failure Points When Engineering a Retrieval Augmented Generation System\\nAuthors: Scott Barnett, Stefanus Kurniawan, Srikanth Thudumu, Zach Brannelly, Mohamed Abdelrazek\\nSummary: Software engineers are increasingly adding semantic search capabilities to\\napplications using a strategy known as Retrieval A', 'id': 'doc_0'}], document_ids={'doc_0'}),\n",
              "  CohereCitation(start=435, end=526, text='Scott Barnett, Stefanus Kurniawan, Srikanth Thudumu, Zach Brannelly, and Mohamed Abdelrazek', documents=[{'output': 'Published: 2024-01-27\\nTitle: MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries\\nAuthors: Yixuan Tang, Yi Yang\\nSummary: Retrieval-augmented generation (RAG) augments large language models (LLM) by\\nretrieving relevant knowledge, showing promising potential in mitigating LLM\\nhallucinations and enhancing response quality, thereby facilitating the great\\nadoption of LLMs in practice. However, we find that existing RAG systems are\\ninadequate in answering multi-hop queries, which require retrieving and\\nreasoning over multiple pieces of supporting evidence. Furthermore, to our\\nknowledge, no existing RAG benchmarking dataset focuses on multi-hop queries.\\nIn this paper, we develop a novel dataset, MultiHop-RAG, which consists of a\\nknowledge base, a large collection of multi-hop queries, their ground-truth\\nanswers, and the associated supporting evidence. We detail the procedure of\\nbuilding the dataset, utilizing an English news article dataset as the\\nunderlying RAG knowledge base. We demonstrate the benchmarking utility of\\nMultiHop-RAG in two experiments. The first experiment compares different\\nembedding models for retrieving evidence for multi-hop queries. In the second\\nexperiment, we examine the capabilities of various state-of-the-art LLMs,\\nincluding GPT-4, PaLM, and Llama2-70B, in reasoning and answering multi-hop\\nqueries given the evidence. Both experiments reveal that existing RAG methods\\nperform unsatisfactorily in retrieving and answering multi-hop queries. We hope\\nMultiHop-RAG will be a valuable resource for the community in developing\\neffective RAG systems, thereby facilitating greater adoption of LLMs in\\npractice. The MultiHop-RAG and implemented RAG system is publicly available at\\nhttps://github.com/yixuantt/MultiHop-RAG/.\\n\\nPublished: 2024-05-02\\nTitle: Retrieval-Augmented Generation for AI-Generated Content: A Survey\\nAuthors: Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao Zhang, Jie Jiang, Bin Cui\\nSummary: Advancements in model algorithms, the growth of foundational models, and\\naccess to high-quality datasets have propelled the evolution of Artificial\\nIntelligence Generated Content (AIGC). Despite its notable successes, AIGC\\nstill faces hurdles such as updating knowledge, handling long-tail data,\\nmitigating data leakage, and managing high training and inference costs.\\nRetrieval-Augmented Generation (RAG) has recently emerged as a paradigm to\\naddress such challenges. In particular, RAG introduces the information\\nretrieval process, which enhances the generation process by retrieving relevant\\nobjects from available data stores, leading to higher accuracy and better\\nrobustness. In this paper, we comprehensively review existing efforts that\\nintegrate RAG technique into AIGC scenarios. We first classify RAG foundations\\naccording to how the retriever augments the generator, distilling the\\nfundamental abstractions of the augmentation methodologies for various\\nretrievers and generators. This unified perspective encompasses all RAG\\nscenarios, illuminating advancements and pivotal technologies that help with\\npotential future progress. We also summarize additional enhancements methods\\nfor RAG, facilitating effective engineering and implementation of RAG systems.\\nThen from another view, we survey on practical applications of RAG across\\ndifferent modalities and tasks, offering valuable references for researchers\\nand practitioners. Furthermore, we introduce the benchmarks for RAG, discuss\\nthe limitations of current RAG systems, and suggest potential directions for\\nfuture research. Github: https://github.com/PKU-DAIR/RAG-Survey.\\n\\nPublished: 2024-01-11\\nTitle: Seven Failure Points When Engineering a Retrieval Augmented Generation System\\nAuthors: Scott Barnett, Stefanus Kurniawan, Srikanth Thudumu, Zach Brannelly, Mohamed Abdelrazek\\nSummary: Software engineers are increasingly adding semantic search capabilities to\\napplications using a strategy known as Retrieval A', 'id': 'doc_0'}], document_ids={'doc_0'}),\n",
              "  CohereCitation(start=530, end=600, text='*RAG: Retrieval Augmented Generation for Knowledge-Intensive NLP Tasks', documents=[{'output': 'Published: 2024-01-27\\nTitle: MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries\\nAuthors: Yixuan Tang, Yi Yang\\nSummary: Retrieval-augmented generation (RAG) augments large language models (LLM) by\\nretrieving relevant knowledge, showing promising potential in mitigating LLM\\nhallucinations and enhancing response quality, thereby facilitating the great\\nadoption of LLMs in practice. However, we find that existing RAG systems are\\ninadequate in answering multi-hop queries, which require retrieving and\\nreasoning over multiple pieces of supporting evidence. Furthermore, to our\\nknowledge, no existing RAG benchmarking dataset focuses on multi-hop queries.\\nIn this paper, we develop a novel dataset, MultiHop-RAG, which consists of a\\nknowledge base, a large collection of multi-hop queries, their ground-truth\\nanswers, and the associated supporting evidence. We detail the procedure of\\nbuilding the dataset, utilizing an English news article dataset as the\\nunderlying RAG knowledge base. We demonstrate the benchmarking utility of\\nMultiHop-RAG in two experiments. The first experiment compares different\\nembedding models for retrieving evidence for multi-hop queries. In the second\\nexperiment, we examine the capabilities of various state-of-the-art LLMs,\\nincluding GPT-4, PaLM, and Llama2-70B, in reasoning and answering multi-hop\\nqueries given the evidence. Both experiments reveal that existing RAG methods\\nperform unsatisfactorily in retrieving and answering multi-hop queries. We hope\\nMultiHop-RAG will be a valuable resource for the community in developing\\neffective RAG systems, thereby facilitating greater adoption of LLMs in\\npractice. The MultiHop-RAG and implemented RAG system is publicly available at\\nhttps://github.com/yixuantt/MultiHop-RAG/.\\n\\nPublished: 2024-05-02\\nTitle: Retrieval-Augmented Generation for AI-Generated Content: A Survey\\nAuthors: Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao Zhang, Jie Jiang, Bin Cui\\nSummary: Advancements in model algorithms, the growth of foundational models, and\\naccess to high-quality datasets have propelled the evolution of Artificial\\nIntelligence Generated Content (AIGC). Despite its notable successes, AIGC\\nstill faces hurdles such as updating knowledge, handling long-tail data,\\nmitigating data leakage, and managing high training and inference costs.\\nRetrieval-Augmented Generation (RAG) has recently emerged as a paradigm to\\naddress such challenges. In particular, RAG introduces the information\\nretrieval process, which enhances the generation process by retrieving relevant\\nobjects from available data stores, leading to higher accuracy and better\\nrobustness. In this paper, we comprehensively review existing efforts that\\nintegrate RAG technique into AIGC scenarios. We first classify RAG foundations\\naccording to how the retriever augments the generator, distilling the\\nfundamental abstractions of the augmentation methodologies for various\\nretrievers and generators. This unified perspective encompasses all RAG\\nscenarios, illuminating advancements and pivotal technologies that help with\\npotential future progress. We also summarize additional enhancements methods\\nfor RAG, facilitating effective engineering and implementation of RAG systems.\\nThen from another view, we survey on practical applications of RAG across\\ndifferent modalities and tasks, offering valuable references for researchers\\nand practitioners. Furthermore, we introduce the benchmarks for RAG, discuss\\nthe limitations of current RAG systems, and suggest potential directions for\\nfuture research. Github: https://github.com/PKU-DAIR/RAG-Survey.\\n\\nPublished: 2024-01-11\\nTitle: Seven Failure Points When Engineering a Retrieval Augmented Generation System\\nAuthors: Scott Barnett, Stefanus Kurniawan, Srikanth Thudumu, Zach Brannelly, Mohamed Abdelrazek\\nSummary: Software engineers are increasingly adding semantic search capabilities to\\napplications using a strategy known as Retrieval A', 'id': 'doc_0'}], document_ids={'doc_0'}),\n",
              "  CohereCitation(start=605, end=642, text='Yixuan Tang, Yi Yang, and Wen-tau Yih', documents=[{'output': 'Published: 2024-01-27\\nTitle: MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries\\nAuthors: Yixuan Tang, Yi Yang\\nSummary: Retrieval-augmented generation (RAG) augments large language models (LLM) by\\nretrieving relevant knowledge, showing promising potential in mitigating LLM\\nhallucinations and enhancing response quality, thereby facilitating the great\\nadoption of LLMs in practice. However, we find that existing RAG systems are\\ninadequate in answering multi-hop queries, which require retrieving and\\nreasoning over multiple pieces of supporting evidence. Furthermore, to our\\nknowledge, no existing RAG benchmarking dataset focuses on multi-hop queries.\\nIn this paper, we develop a novel dataset, MultiHop-RAG, which consists of a\\nknowledge base, a large collection of multi-hop queries, their ground-truth\\nanswers, and the associated supporting evidence. We detail the procedure of\\nbuilding the dataset, utilizing an English news article dataset as the\\nunderlying RAG knowledge base. We demonstrate the benchmarking utility of\\nMultiHop-RAG in two experiments. The first experiment compares different\\nembedding models for retrieving evidence for multi-hop queries. In the second\\nexperiment, we examine the capabilities of various state-of-the-art LLMs,\\nincluding GPT-4, PaLM, and Llama2-70B, in reasoning and answering multi-hop\\nqueries given the evidence. Both experiments reveal that existing RAG methods\\nperform unsatisfactorily in retrieving and answering multi-hop queries. We hope\\nMultiHop-RAG will be a valuable resource for the community in developing\\neffective RAG systems, thereby facilitating greater adoption of LLMs in\\npractice. The MultiHop-RAG and implemented RAG system is publicly available at\\nhttps://github.com/yixuantt/MultiHop-RAG/.\\n\\nPublished: 2024-05-02\\nTitle: Retrieval-Augmented Generation for AI-Generated Content: A Survey\\nAuthors: Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao Zhang, Jie Jiang, Bin Cui\\nSummary: Advancements in model algorithms, the growth of foundational models, and\\naccess to high-quality datasets have propelled the evolution of Artificial\\nIntelligence Generated Content (AIGC). Despite its notable successes, AIGC\\nstill faces hurdles such as updating knowledge, handling long-tail data,\\nmitigating data leakage, and managing high training and inference costs.\\nRetrieval-Augmented Generation (RAG) has recently emerged as a paradigm to\\naddress such challenges. In particular, RAG introduces the information\\nretrieval process, which enhances the generation process by retrieving relevant\\nobjects from available data stores, leading to higher accuracy and better\\nrobustness. In this paper, we comprehensively review existing efforts that\\nintegrate RAG technique into AIGC scenarios. We first classify RAG foundations\\naccording to how the retriever augments the generator, distilling the\\nfundamental abstractions of the augmentation methodologies for various\\nretrievers and generators. This unified perspective encompasses all RAG\\nscenarios, illuminating advancements and pivotal technologies that help with\\npotential future progress. We also summarize additional enhancements methods\\nfor RAG, facilitating effective engineering and implementation of RAG systems.\\nThen from another view, we survey on practical applications of RAG across\\ndifferent modalities and tasks, offering valuable references for researchers\\nand practitioners. Furthermore, we introduce the benchmarks for RAG, discuss\\nthe limitations of current RAG systems, and suggest potential directions for\\nfuture research. Github: https://github.com/PKU-DAIR/RAG-Survey.\\n\\nPublished: 2024-01-11\\nTitle: Seven Failure Points When Engineering a Retrieval Augmented Generation System\\nAuthors: Scott Barnett, Stefanus Kurniawan, Srikanth Thudumu, Zach Brannelly, Mohamed Abdelrazek\\nSummary: Software engineers are increasingly adding semantic search capabilities to\\napplications using a strategy known as Retrieval A', 'id': 'doc_0'}], document_ids={'doc_0'}),\n",
              "  CohereCitation(start=646, end=716, text='*RAG-Token: Retrieval Augmented Generation with Token-Level Retrievers', documents=[{'output': 'Published: 2024-01-27\\nTitle: MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries\\nAuthors: Yixuan Tang, Yi Yang\\nSummary: Retrieval-augmented generation (RAG) augments large language models (LLM) by\\nretrieving relevant knowledge, showing promising potential in mitigating LLM\\nhallucinations and enhancing response quality, thereby facilitating the great\\nadoption of LLMs in practice. However, we find that existing RAG systems are\\ninadequate in answering multi-hop queries, which require retrieving and\\nreasoning over multiple pieces of supporting evidence. Furthermore, to our\\nknowledge, no existing RAG benchmarking dataset focuses on multi-hop queries.\\nIn this paper, we develop a novel dataset, MultiHop-RAG, which consists of a\\nknowledge base, a large collection of multi-hop queries, their ground-truth\\nanswers, and the associated supporting evidence. We detail the procedure of\\nbuilding the dataset, utilizing an English news article dataset as the\\nunderlying RAG knowledge base. We demonstrate the benchmarking utility of\\nMultiHop-RAG in two experiments. The first experiment compares different\\nembedding models for retrieving evidence for multi-hop queries. In the second\\nexperiment, we examine the capabilities of various state-of-the-art LLMs,\\nincluding GPT-4, PaLM, and Llama2-70B, in reasoning and answering multi-hop\\nqueries given the evidence. Both experiments reveal that existing RAG methods\\nperform unsatisfactorily in retrieving and answering multi-hop queries. We hope\\nMultiHop-RAG will be a valuable resource for the community in developing\\neffective RAG systems, thereby facilitating greater adoption of LLMs in\\npractice. The MultiHop-RAG and implemented RAG system is publicly available at\\nhttps://github.com/yixuantt/MultiHop-RAG/.\\n\\nPublished: 2024-05-02\\nTitle: Retrieval-Augmented Generation for AI-Generated Content: A Survey\\nAuthors: Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao Zhang, Jie Jiang, Bin Cui\\nSummary: Advancements in model algorithms, the growth of foundational models, and\\naccess to high-quality datasets have propelled the evolution of Artificial\\nIntelligence Generated Content (AIGC). Despite its notable successes, AIGC\\nstill faces hurdles such as updating knowledge, handling long-tail data,\\nmitigating data leakage, and managing high training and inference costs.\\nRetrieval-Augmented Generation (RAG) has recently emerged as a paradigm to\\naddress such challenges. In particular, RAG introduces the information\\nretrieval process, which enhances the generation process by retrieving relevant\\nobjects from available data stores, leading to higher accuracy and better\\nrobustness. In this paper, we comprehensively review existing efforts that\\nintegrate RAG technique into AIGC scenarios. We first classify RAG foundations\\naccording to how the retriever augments the generator, distilling the\\nfundamental abstractions of the augmentation methodologies for various\\nretrievers and generators. This unified perspective encompasses all RAG\\nscenarios, illuminating advancements and pivotal technologies that help with\\npotential future progress. We also summarize additional enhancements methods\\nfor RAG, facilitating effective engineering and implementation of RAG systems.\\nThen from another view, we survey on practical applications of RAG across\\ndifferent modalities and tasks, offering valuable references for researchers\\nand practitioners. Furthermore, we introduce the benchmarks for RAG, discuss\\nthe limitations of current RAG systems, and suggest potential directions for\\nfuture research. Github: https://github.com/PKU-DAIR/RAG-Survey.\\n\\nPublished: 2024-01-11\\nTitle: Seven Failure Points When Engineering a Retrieval Augmented Generation System\\nAuthors: Scott Barnett, Stefanus Kurniawan, Srikanth Thudumu, Zach Brannelly, Mohamed Abdelrazek\\nSummary: Software engineers are increasingly adding semantic search capabilities to\\napplications using a strategy known as Retrieval A', 'id': 'doc_0'}], document_ids={'doc_0'}),\n",
              "  CohereCitation(start=721, end=758, text='Yixuan Tang, Yi Yang, and Wen-tau Yih', documents=[{'output': 'Published: 2024-01-27\\nTitle: MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries\\nAuthors: Yixuan Tang, Yi Yang\\nSummary: Retrieval-augmented generation (RAG) augments large language models (LLM) by\\nretrieving relevant knowledge, showing promising potential in mitigating LLM\\nhallucinations and enhancing response quality, thereby facilitating the great\\nadoption of LLMs in practice. However, we find that existing RAG systems are\\ninadequate in answering multi-hop queries, which require retrieving and\\nreasoning over multiple pieces of supporting evidence. Furthermore, to our\\nknowledge, no existing RAG benchmarking dataset focuses on multi-hop queries.\\nIn this paper, we develop a novel dataset, MultiHop-RAG, which consists of a\\nknowledge base, a large collection of multi-hop queries, their ground-truth\\nanswers, and the associated supporting evidence. We detail the procedure of\\nbuilding the dataset, utilizing an English news article dataset as the\\nunderlying RAG knowledge base. We demonstrate the benchmarking utility of\\nMultiHop-RAG in two experiments. The first experiment compares different\\nembedding models for retrieving evidence for multi-hop queries. In the second\\nexperiment, we examine the capabilities of various state-of-the-art LLMs,\\nincluding GPT-4, PaLM, and Llama2-70B, in reasoning and answering multi-hop\\nqueries given the evidence. Both experiments reveal that existing RAG methods\\nperform unsatisfactorily in retrieving and answering multi-hop queries. We hope\\nMultiHop-RAG will be a valuable resource for the community in developing\\neffective RAG systems, thereby facilitating greater adoption of LLMs in\\npractice. The MultiHop-RAG and implemented RAG system is publicly available at\\nhttps://github.com/yixuantt/MultiHop-RAG/.\\n\\nPublished: 2024-05-02\\nTitle: Retrieval-Augmented Generation for AI-Generated Content: A Survey\\nAuthors: Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao Zhang, Jie Jiang, Bin Cui\\nSummary: Advancements in model algorithms, the growth of foundational models, and\\naccess to high-quality datasets have propelled the evolution of Artificial\\nIntelligence Generated Content (AIGC). Despite its notable successes, AIGC\\nstill faces hurdles such as updating knowledge, handling long-tail data,\\nmitigating data leakage, and managing high training and inference costs.\\nRetrieval-Augmented Generation (RAG) has recently emerged as a paradigm to\\naddress such challenges. In particular, RAG introduces the information\\nretrieval process, which enhances the generation process by retrieving relevant\\nobjects from available data stores, leading to higher accuracy and better\\nrobustness. In this paper, we comprehensively review existing efforts that\\nintegrate RAG technique into AIGC scenarios. We first classify RAG foundations\\naccording to how the retriever augments the generator, distilling the\\nfundamental abstractions of the augmentation methodologies for various\\nretrievers and generators. This unified perspective encompasses all RAG\\nscenarios, illuminating advancements and pivotal technologies that help with\\npotential future progress. We also summarize additional enhancements methods\\nfor RAG, facilitating effective engineering and implementation of RAG systems.\\nThen from another view, we survey on practical applications of RAG across\\ndifferent modalities and tasks, offering valuable references for researchers\\nand practitioners. Furthermore, we introduce the benchmarks for RAG, discuss\\nthe limitations of current RAG systems, and suggest potential directions for\\nfuture research. Github: https://github.com/PKU-DAIR/RAG-Survey.\\n\\nPublished: 2024-01-11\\nTitle: Seven Failure Points When Engineering a Retrieval Augmented Generation System\\nAuthors: Scott Barnett, Stefanus Kurniawan, Srikanth Thudumu, Zach Brannelly, Mohamed Abdelrazek\\nSummary: Software engineers are increasingly adding semantic search capabilities to\\napplications using a strategy known as Retrieval A', 'id': 'doc_0'}], document_ids={'doc_0'})]}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "es0FVPAv9fui"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}